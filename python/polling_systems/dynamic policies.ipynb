{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4a2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PollingSystem as ps\n",
    "import StaticRP as srp\n",
    "import MarkovianRP as mrp\n",
    "import dynamic_rp as drp\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bea266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up a simple, symmetric polling system\n",
    "sys_traffic = 0.1\n",
    "beta = 1\n",
    "lambdas = np.array([1/3, 1/3, 1/3])*sys_traffic/beta\n",
    "sym_sys = ps.PollingSystem(lambdas, beta)\n",
    "S = np.array([[0, 3, 3],\n",
    "              [3, 0, 3],\n",
    "              [3, 3, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a105c867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333 0.33333333 0.33333333] 6.000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/win/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py:282: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 5.96448012e-04 9.99403552e-01]\n",
      " [9.99357140e-01 0.00000000e+00 6.42860424e-04]\n",
      " [8.67015555e-04 9.99132984e-01 0.00000000e+00]] 4.891229361880553\n"
     ]
    }
   ],
   "source": [
    "pi, w_rnd = sym_sys.calc_optimal_rp(S, rp_type = 0)\n",
    "print(pi, w_rnd)\n",
    "static_rand = mrp.RandomRP(pi)\n",
    "P, w_mrkv = sym_sys.calc_optimal_rp(S, rp_type = 1)\n",
    "print(P, w_mrkv)\n",
    "static_markov = mrp.MarkovianRP(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479b13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_policy = srp.MinSSRPFromPis(pi, S)\n",
    "cyclic_policy = srp.StaticRP(np.array([0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb526c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rule = drp.DPRP(lambdas, beta, S, drp.shortest_lengths)\n",
    "simple_rule_time_diffs = drp.DPRP(lambdas, beta, S, drp.shortest_lengths, fully_observed = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877951a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.130351785655419\n",
      "5.021332150830562\n",
      "4.911448810566129\n",
      "4.894449480339737\n",
      "3.938393616062812\n",
      "4.964796373717104\n"
     ]
    }
   ],
   "source": [
    "#now simulate and compare\n",
    "t = 2*60*60\n",
    "xt1, wt1, _, _, _, _, _  = sym_sys.simulate(static_rand, S, t)\n",
    "print(wt1[-1][1])\n",
    "xt2, wt2, _, _, _, _, _  = sym_sys.simulate(static_markov, S, t)\n",
    "print(wt2[-1][1])\n",
    "xt3, wt3, _, _, _, _, _  = sym_sys.simulate(table_policy, S, t)\n",
    "print(wt3[-1][1])\n",
    "xt4, wt4, _, _, _, _, _  = sym_sys.simulate(cyclic_policy, S, t)\n",
    "print(wt4[-1][1])\n",
    "xt5, wt5, _, _, _, _, _  = sym_sys.simulate(simple_rule, S, t)\n",
    "print(wt5[-1][1])\n",
    "xt6, wt6, _, _, _, _, _  = sym_sys.simulate(simple_rule_time_diffs, S, t, fully_observed = False)\n",
    "print(wt6[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6db29d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 120.00 minutes\n"
     ]
    }
   ],
   "source": [
    "#now let's look at a nice little MCTS\n",
    "\n",
    "K = 7200\n",
    "T = K*beta#(Two hours, since beta = 1)\n",
    "print(\"Total time: %.2f minutes\"%(T/60))\n",
    "\n",
    "\n",
    "class PSState:\n",
    "    def __init__(self, q, q_lengths, k):\n",
    "        self.q = q\n",
    "        self.q_lengths = q_lengths\n",
    "        self.k = k\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        #todo some sanity cheques\n",
    "        return self.q == other.q and all(self.q_lengths == other.q_lengths) and self.k = other.k\n",
    "    \n",
    "class MCTSNode:\n",
    "    \n",
    "    def __init__(self, state):\n",
    "        self.state = state\n",
    "        #at decision points, queue q will be empty, don't allow it as a choice\n",
    "        self.actions = [i for i in range(len(state.q_lengths)) if i != state.q]\n",
    "        self.a_vists = {}\n",
    "        self.visits = 0\n",
    "        #map from actions to value\n",
    "        self.est_future_vals = {}#plug in expected value of integral if possible\n",
    "        self.stage_vals = {}#plug in expected value of integral if possible\n",
    "        #map from child actions to lists of possible children (there will be multiple per action)\n",
    "        self.children = {}\n",
    "        \n",
    "    def getUCB1Action(self):\n",
    "        #todo - handle unvisited if numpy can't\n",
    "        #TODO - double check that just making this a minus is ok when we're minimizing\n",
    "        ucb_vals = [self.est_values[a] - np.sqrt(2*np.log(self.n_vists)/self.a_vists[a]) for a in self.actions]\n",
    "        argmin = np.argmin(ucb_vals)\n",
    "        return self.actions[argmin]\n",
    "    \n",
    "    def addFutureReward(a, r):\n",
    "        n = self.a_visits[a]\n",
    "        current_est = self.est_future_vals[a]\n",
    "        self.est_future_vals[a] = (n*current_est + r)/(n+1)\n",
    "        self.a_visits[a] += 1\n",
    "        \n",
    "class MCTSTree:\n",
    "    \n",
    "    def __init__(self, root, ps, S, K):\n",
    "        self.root = root\n",
    "        self.ps\n",
    "        self.S\n",
    "        #eventually, should probably use a better data structure\n",
    "        #TODO intialize states to empty maps\n",
    "        self.nodes = {}\n",
    "        self.nodes[root.state.q] = [root]\n",
    "        self.K = k\n",
    "        \n",
    "    def nextNode(self):\n",
    "        node = self.root\n",
    "        ex_node = None\n",
    "        while not found_unexpanded_node:\n",
    "            next_action = node.getUCB1Action()\n",
    "            path.append( (node, next_action) )\n",
    "            state  = node.state\n",
    "            q_next, new_q_lengths, time = self.ps.stageTransitionRealization(state.q, state.q_lengths, next_action, self.S)\n",
    "            #check if this state is in out set of states\n",
    "            new_state = PSState(q_next, new_q_lengths, state.k + time//ps.beta)\n",
    "            #first check if it's in the nodes set of children\n",
    "            child_states = [mctsnode.state for mctsnode in node.children[next_action]]\n",
    "            if new_state in child_states:\n",
    "                nidx = child_states.index(new_state)\n",
    "                node = node.children[next_action][nidx]\n",
    "            #check if it's somewhere else to for more efficient use of simulations\n",
    "            elif new_state in [mctsn.state for mctsn in self.nodes[q_next]]:\n",
    "                \n",
    "                nidx = [mctsn.state for mctsn in self.nodes[q_next]].index(new_state)\n",
    "                nxt_node = self.states[q_next][nidx]\n",
    "                node.children[next_action].append(nxt_node)\n",
    "                node = nxt_node\n",
    "            #ok we haven't seen this before\n",
    "            else:\n",
    "                found_unexpanded_node = True\n",
    "                nxt_node = MCTSNode(new_state)\n",
    "                node.children[next_action].append(nxt_node)\n",
    "                self.nodes[q_next].append(nxt_node)\n",
    "                node = nxt_node\n",
    "        return path, ex_node\n",
    "            \n",
    "    def expand(self, ex_node, dflt_policy):\n",
    "        state = ex_node.state\n",
    "        #TODO, handle non-zero initial queue lengths\n",
    "        #handle fact that first stage of the simulation\n",
    "        #, its epxectation can be computed explicitly, so we leave it out\n",
    "        # so we actually want to select a random state we arrive at after switching\n",
    "        #and start simulations from there\n",
    "        q_next = dflt_policy.next(state.q, state.q_lengths)\n",
    "        q_start, lens_start, time = self.ps.stageTransitionRealization(state.q, state.q_lengths, q_next, self.S)\n",
    "        xt, _, _, _, _, _, _ = self.ps.simulate(dflt_policy, self.S,\n",
    "                                beta*(self.K) - time, q = q_start,\n",
    "                                q_lengths = lens_start )\n",
    "        int_L = MCTSTree.integrate_q_lengths(xt)\n",
    "        return int_L, q_next\n",
    "        \n",
    "    def backProp(self, val, path):\n",
    "        future_reward = val\n",
    "        for (node, action ) in path[::-1]:\n",
    "            node.addFutureReward(action, future_reward)\n",
    "            future_reward += node.stage_vals[action]\n",
    "    \n",
    "    def integrate_q_lengths(xt):\n",
    "        int_L = 0\n",
    "        xt = np.array(xt)\n",
    "        times = xt[0]\n",
    "        total_length = np.sum(xt[2:], axis = 1)\n",
    "        #todo - double check this matches how xt is created\n",
    "        return total_length[:-1] @ (times[1:] - times[:-1])\n",
    "        \n",
    "x0 = PSState(0, np.zeros(3), 0)\n",
    "root = MCTSNode(x0)\n",
    "tree = MCTSTree(root)\n",
    "\n",
    "while not converged:\n",
    "    #find next node to expand\n",
    "    path, ex_node = tree.nextNode()\n",
    "    #rollout\n",
    "    val, action = tree.expand(ex_node, dflt_policy)\n",
    "    path.append((ex_node, action))\n",
    "    tree.backProp(val, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5dd5ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f631ba53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
